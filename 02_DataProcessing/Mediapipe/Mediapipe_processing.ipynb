{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"How to build a motion tracking pipeline: Processing MediaPipe coordinates\"\n",
    "authors: Gillian Rosenberg, Šárka Kadavá\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed motion tracking with MediaPipe and now we have saved coordinates for each file in a csv file.\n",
    "\n",
    "There are important things to do before we can actually start any analysis. But let's take it step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import platform  # To detect the operating system\n",
    "\n",
    "# Get the current working directory\n",
    "curfolder = os.getcwd()\n",
    "\n",
    "user = \"Windows\"\n",
    "\n",
    "# Check the OS type\n",
    "if user == \"Windows\":\n",
    "    mtfolder = curfolder + '\\\\..\\\\..\\\\01_MotionCapture\\\\Mediapipe\\\\Output_TimeSeries\\\\'\n",
    "    vidfolder = curfolder + '\\\\..\\\\..\\\\01_MotionCapture\\\\Mediapipe\\\\Output_Videos\\\\'\n",
    "elif user == \"Mac\":  # Darwin is the system name for macOS\n",
    "    mtfolder = os.path.join(curfolder, '..', '..', '01_MotionCapture', 'Mediapipe', 'Output_TimeSeries')\n",
    "    vidfolder = os.path.join(curfolder, '..', '..', '01_MotionCapture', 'Mediapipe', 'Output_Videos')\n",
    "else:\n",
    "    raise SystemError(\"Unsupported operating system\")\n",
    "\n",
    "# Get all the files in the folder\n",
    "mtfiles = glob.glob(os.path.join(mtfolder, '*body_world.csv'))  # Use os.path.join for compatibility\n",
    "print(mtfiles)\n",
    "\n",
    "vidfiles = glob.glob(os.path.join(vidfolder, '*.avi'))\n",
    "print(vidfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by inspecting one file. (TIP: Inspect in Data Wranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in one file\n",
    "sample = pd.read_csv(mtfiles[0])\n",
    "sample.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of columns do we see?\n",
    "In what time interval are we saving the coordinates? What is our sampling rate?\n",
    "What do x, y, z coordinates represent?\n",
    "What is visibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we familiarized ourselves with the data, we can start step by step cleaning it.\n",
    "\n",
    "For example, let's say we don't need the visibility column. It might be useful for some specific cases, but for now, we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop visibility cols\n",
    "sample = sample.drop(sample.columns[sample.columns.str.contains('visibility',case = False)],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we conventiently reduced the number of columns to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check how do coordinates look like, for example for right wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x, y, z for RIGHT_WRIST\n",
    "sample['Y_RIGHT_WRIST'].plot()\n",
    "sample['X_RIGHT_WRIST'].plot()\n",
    "sample['Z_RIGHT_WRIST'].plot()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check back to the video, so we can understand what do these coordinates represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the video we need to look at \n",
    "mtfiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see? \n",
    "What does y-axis represent?\n",
    "Do you notice something weird?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we need to....\n",
    "\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipping the data\n",
    "\n",
    "In MediaPipe, for some reason the y-axis and z-axis are flipped. Who knows what is the reason, but for us this serves as a good example of why we **always** need to check our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to flip the data\n",
    "def flip_data(df):\n",
    "    cols = df.columns\n",
    "    cols  = [col for col in df.columns if 'Y_' in col]\n",
    "    cols = list(cols)\n",
    "        # first get the vertical height of the configuration\n",
    "        # we only do this for the first frame; the transformation will be applied to all frames\n",
    "    maxpoint = []\n",
    "    for joint in cols:\n",
    "        maxpoint.append(df.loc[0, joint])\n",
    "        # iterate over each joint, in each frame, to flip the y-axis\n",
    "    for frame in range(len(df)):\n",
    "        for joint in cols:\n",
    "            ytrans = max(maxpoint) - df.loc[frame, joint] - 1\n",
    "            df.loc[frame, joint] = ytrans\n",
    "    return df\n",
    "\n",
    "# use it on the file\n",
    "sample = flip_data(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check\n",
    "\n",
    "sample['Y_RIGHT_WRIST'].plot()\n",
    "sample['X_RIGHT_WRIST'].plot()\n",
    "sample['Z_RIGHT_WRIST'].plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolating the data\n",
    "\n",
    "This will be video-specific problem, but sometimes we might encounter that there are missing data points - for example, when one arm covers the other, or when arms cover the face, etc. If these missing windows are of reasonable length, we can **interpolate** them. Interpolation is a method that estimates a missing value based on the values of the surrounding data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the data\n",
    "def interpolate(sample):\n",
    "    cols = sample.columns\n",
    "\n",
    "    # put away time from cols\n",
    "    cols = cols.drop(['time'])\n",
    "\n",
    "    # loop over the cols and interpolate missing data\n",
    "    for col in cols:\n",
    "        sample[col] = sample[col].interpolate(method='linear', x = sample['time'], limit=10) # limit is the max number of missing values to fill\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# use it on the file\n",
    "sample = interpolate(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing the data\n",
    "\n",
    "Looking at the plots, you may notice that the data is quite noisy and jerky. This is because we are collecting each value for a keypoint at certain frame rate - for us it is ca. 16 ms. \n",
    "\n",
    "We can **smooth** the data with various filters - Butterworth, Savitzky-Golay, etc.\n",
    "\n",
    "In this script, we will be using **Savitzky-Golay filter**. This filter fits a *x-order* polynomial to a sequence of data points and then evaluates the polynomial at the central point of the sequence. This is repeated for on sequence of *windows*. This allows us to smooth the data without losing the original shape of the curve.\n",
    "\n",
    "When using this filter, we need to specify the *window* and *order* parameters. The *window* parameter specifies the number of data points used to fit the polynomial, while the *order* parameter specifies the order of the polynomial.\n",
    "\n",
    "So now the question arises - HOW TO CHOOSE THOSE???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we are not going to blindly guess. We can just try different combinations and see which are smoothing the data approprietly, without losing too much of the original shape of the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check different smoothing windows and orders\n",
    "def check_smooth_strength(df, windows, orders, keytoplot):\n",
    "\n",
    "    # prepare new df\n",
    "    df_smooth = pd.DataFrame()\n",
    "\n",
    "    for win in windows:\n",
    "        for ord in orders:\n",
    "            df_smooth[keytoplot + '_savgol' + str(win) + '_' + str(ord)] = scipy.signal.savgol_filter(df[keytoplot], win, ord)\n",
    "\n",
    "    # make R_Hand_x from df_sample a list\n",
    "    keytoplot_unsmoothed = df[keytoplot].tolist()\n",
    "\n",
    "    # load these values into df_smooth as a new column\n",
    "    df_smooth[keytoplot] = keytoplot_unsmoothed\n",
    "\n",
    "    # plot keytoplot in all strngths\n",
    "    colstoplot = [x for x in df_smooth.columns if keytoplot in x]\n",
    "    plt.figure()\n",
    "    for col in colstoplot:\n",
    "        plt.plot(df_smooth[col], label=col)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [15, 25, 35] # list possible window\n",
    "orders = [1, 2, 3] # list possible orders\n",
    "\n",
    "check_smooth_strength(sample, windows, orders, 'X_RIGHT_WRIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you comment on some of the different combinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the data\n",
    "def smooth_data(sample):\n",
    "    cols_upperbody = ['X_NOSE', 'Y_NOSE', 'Z_NOSE', 'X_LEFT_EYE_INNER', 'Y_LEFT_EYE_INNER', 'Z_LEFT_EYE_INNER', 'X_LEFT_EYE', 'Y_LEFT_EYE', 'Z_LEFT_EYE', 'X_LEFT_EYE_OUTER', 'Y_LEFT_EYE_OUTER', 'Z_LEFT_EYE_OUTER', 'X_RIGHT_EYE_OUTER', 'Y_RIGHT_EYE_OUTER', 'Z_RIGHT_EYE_OUTER', 'X_RIGHT_EYE', 'Y_RIGHT_EYE', 'Z_RIGHT_EYE', 'X_RIGHT_EYE_OUTER.1', 'Y_RIGHT_EYE_OUTER.1', 'Z_RIGHT_EYE_OUTER.1', 'X_LEFT_EAR', 'Y_LEFT_EAR', 'Z_LEFT_EAR', 'X_RIGHT_EAR', 'Y_RIGHT_EAR', 'Z_RIGHT_EAR', 'X_MOUTH_LEFT', 'Y_MOUTH_LEFT', 'Z_MOUTH_LEFT', 'X_MOUTH_RIGHT', 'Y_MOUTH_RIGHT', 'Z_MOUTH_RIGHT', 'X_LEFT_SHOULDER', 'Y_LEFT_SHOULDER', 'Z_LEFT_SHOULDER', 'X_RIGHT_SHOULDER', 'Y_RIGHT_SHOULDER', 'Z_RIGHT_SHOULDER', 'X_LEFT_ELBOW', 'Y_LEFT_ELBOW', 'Z_LEFT_ELBOW', 'X_RIGHT_ELBOW', 'Y_RIGHT_ELBOW', 'Z_RIGHT_ELBOW', 'X_LEFT_WRIST', 'Y_LEFT_WRIST', 'Z_LEFT_WRIST', 'X_RIGHT_WRIST', 'Y_RIGHT_WRIST', 'Z_RIGHT_WRIST', 'X_LEFT_PINKY', 'Y_LEFT_PINKY', 'Z_LEFT_PINKY', 'X_RIGHT_PINKY', 'Y_RIGHT_PINKY', 'Z_RIGHT_PINKY', 'X_LEFT_INDEX', 'Y_LEFT_INDEX', 'Z_LEFT_INDEX', 'X_RIGHT_INDEX', 'Y_RIGHT_INDEX', 'Z_RIGHT_INDEX', 'X_LEFT_THUMB', 'Y_LEFT_THUMB', 'Z_LEFT_THUMB', 'X_RIGHT_THUMB', 'Y_RIGHT_THUMB']\n",
    "    cols_lowerbody = ['X_LEFT_HIP',\n",
    "       'Y_LEFT_HIP', 'Z_LEFT_HIP', 'X_RIGHT_HIP', 'Y_RIGHT_HIP', 'Z_RIGHT_HIP',\n",
    "       'X_LEFT_KNEE', 'Y_LEFT_KNEE', 'Z_LEFT_KNEE', 'X_RIGHT_KNEE',\n",
    "       'Y_RIGHT_KNEE', 'Z_RIGHT_KNEE', 'X_LEFT_ANKLE', 'Y_LEFT_ANKLE',\n",
    "       'Z_LEFT_ANKLE', 'X_RIGHT_ANKLE', 'Y_RIGHT_ANKLE', 'Z_RIGHT_ANKLE',\n",
    "       'X_LEFT_HEEL', 'Y_LEFT_HEEL', 'Z_LEFT_HEEL', 'X_RIGHT_HEEL',\n",
    "       'Y_RIGHT_HEEL', 'Z_RIGHT_HEEL', 'X_LEFT_FOOT_INDEX',\n",
    "       'Y_LEFT_FOOT_INDEX', 'Z_LEFT_FOOT_INDEX', 'X_RIGHT_FOOT_INDEX',\n",
    "       'Y_RIGHT_FOOT_INDEX', 'Z_RIGHT_FOOT_INDEX']\n",
    "\n",
    "# smooth upperbody and face with savgol 20,4\n",
    "    for col in cols_upperbody:\n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 30, 1)\n",
    "\n",
    "# smooth lowerbod with savgol 30,3\n",
    "    for col in cols_lowerbody:  \n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 30, 1)\n",
    "    return(sample)\n",
    "\n",
    "# use it on the file\n",
    "sample = smooth_data(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting derivatives\n",
    "\n",
    "Now we are almost done! We have cleaned the data, interpolated it, smoothed it... and most likely, we want for analysis something more than just coordinates. \n",
    "\n",
    "Coordinates represent positional data. We can get more information from the data by calculating **the derivatives**. Derivatives represent the rate of change of a function at a given point.\n",
    "\n",
    "First derivate of positional data represents the rate of change of the position. This means ....\n",
    "Second derivate of positional data represents the rate of change of the rate of change of the position. This means ....\n",
    "Third derivate of positional data represents the rate of change of the rate of change of the rate of change of the position. This means ....\n",
    "\n",
    "Below, you can see functions that always have the same pipeline:\n",
    "- collecting columns to be differentiated\n",
    "- differentiating them\n",
    "- smoothing the differentiated signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, notice one thing in the code:\n",
    "\n",
    "```python\n",
    "\n",
    "sample[col + '_speed'] = sample[col + '_speed']*sr\n",
    "\n",
    "```\n",
    "\n",
    "It seems that we are multiplying the speed by the sampling rate. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 3D SPEED #############\n",
    "def derive_speed_smooth(cols, sample, sr):\n",
    "    speedcols = [col.replace('Y_', '') for col in cols]\n",
    "    speedcols = [col.replace('X_', '') for col in speedcols]\n",
    "    speedcols = [col.replace('Z_', '') for col in speedcols]\n",
    "\n",
    "# keep only unique values\n",
    "    speedcols = list(set(speedcols))\n",
    "\n",
    "    for col in speedcols:\n",
    "        x = sample['X_' + col]\n",
    "        y = sample['Y_' + col]\n",
    "        z = sample['Z_' + col]\n",
    "\n",
    "    # calculate speed\n",
    "        sample[col + '_speed'] = np.insert(np.sqrt(np.diff(x) ** 2 + np.diff(y) ** 2 + np.diff(z) ** 2), 0, 0)\n",
    "        sample[col + '_speed'] = sample[col + '_speed']*sr\n",
    "    # smooth speed:\n",
    "    for col in speedcols:\n",
    "        sample[col + '_speed'] = scipy.signal.savgol_filter(sample[col + '_speed'], 20, 4)\n",
    "\n",
    "    return(speedcols, sample)\n",
    "\n",
    "######### 2D SPEED #############\n",
    "def derive_2dspeed_smooth(cols, sample, sr):\n",
    "    speedcols = [col.replace('Y_', '') for col in cols]\n",
    "    speedcols = [col.replace('X_', '') for col in speedcols]\n",
    "\n",
    "    # keep only unique values\n",
    "    speedcols = list(set(speedcols))\n",
    "\n",
    "    for col in speedcols:\n",
    "        x = sample['X_' + col]\n",
    "        y = sample['Y_' + col]\n",
    "\n",
    "        # calculate speed\n",
    "        sample[col + '_speed2D'] = np.insert(np.sqrt(np.diff(x) ** 2 + np.diff(y) ** 2), 0, 0)\n",
    "        sample[col + '_speed2D'] = sample[col + '_speed2D']*sr\n",
    "        \n",
    "    #  smooth speed:\n",
    "    for col in speedcols:\n",
    "        sample[col + '_speed2D'] = scipy.signal.savgol_filter(sample[col + '_speed2D'], 20, 4)\n",
    "\n",
    "    return(speedcols, sample)\n",
    "\n",
    "######### 1D VERTICAL VELOCITY #############\n",
    "def derive_vertical_vel_smooth(sample):\n",
    "    verticalcols = [col for col in sample.columns if 'Y_' in col]\n",
    "    verticalcols = [col for col in verticalcols if 'speed' not in col]\n",
    "\n",
    "# calculate the velocity\n",
    "    for col in verticalcols:\n",
    "        sample[col + '_velocity'] = np.insert(np.diff(sample[col]), 0, 0)  \n",
    "    vel_cols = [col for col in sample.columns if \"_velocity\" in col]\n",
    "    for col in vel_cols:\n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 20, 4)\n",
    "    return verticalcols, sample\n",
    "\n",
    "######### 3D ACCELERATION #############\n",
    "def derive_accel_smooth(speedcols, sample):\n",
    "    for col in speedcols:\n",
    "        sample[col + '_acceleration'] = np.insert(np.diff(sample[col + \"_speed\"]), 0, 0) \n",
    "    accel_cols = [col for col in sample.columns if \"_acceleration\" in col]\n",
    "    for col in accel_cols:\n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 20, 4)\n",
    "    return (sample)\n",
    "\n",
    "######### 2D ACCELERATION #############\n",
    "def derive_accel2D_smooth(speedcols, sample):\n",
    "    for col in speedcols:\n",
    "        sample[col + '_acceleration2D'] = np.insert(np.diff(sample[col + \"_speed2D\"]), 0, 0) \n",
    "    accel_cols = [col for col in sample.columns if \"_acceleration2D\" in col]\n",
    "    for col in accel_cols:\n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 20, 4)\n",
    "    return (sample)\n",
    "\n",
    "######### 3D JERK #############\n",
    "def derive_jerk_smooth(speedcols, sample):\n",
    "    # calcuates the jerk for each vertical column\n",
    "    for col in speedcols:\n",
    "        sample[col + '_jerk'] = np.insert(np.diff(sample[col + \"_acceleration\"]), 0, 0)\n",
    "    # gets a list of all jerk columns\n",
    "    jerk_cols = [col for col in sample.columns if \"_jerk\" in col]\n",
    "    # smooths all jerk columns\n",
    "    for col in jerk_cols:\n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 20, 4)\n",
    "    return (sample)\n",
    "\n",
    "######### 2D JERK #############\n",
    "def derive_jerk2D_smooth(speedcols, sample):\n",
    "    # calcuates the jerk for each vertical column\n",
    "    for col in speedcols:\n",
    "        sample[col + '_jerk2D'] = np.insert(np.diff(sample[col + \"_acceleration2D\"]), 0, 0)\n",
    "    # gets a list of all jerk columns\n",
    "    jerk_cols = [col for col in sample.columns if \"_jerk2D\" in col]\n",
    "    # smooths all jerk columns\n",
    "    for col in jerk_cols:\n",
    "        sample[col] = scipy.signal.savgol_filter(sample[col], 20, 4)\n",
    "    return (sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is our sr\n",
    "sr = 1/np.mean(np.diff(sample['time'])) # average time interval (difference) between consecutive frames\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what unit is this sampling rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the 3D derivates on our sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute derivatives\n",
    "\n",
    "# we want to differentiate all columns except time\n",
    "cols = sample.columns\n",
    "cols = cols.drop(['time'])\n",
    "\n",
    "# 3D speed\n",
    "speedcols, sample = derive_speed_smooth(cols, sample, sr)\n",
    "\n",
    "# 3D acceleration\n",
    "sample = derive_accel_smooth(speedcols, sample)\n",
    "\n",
    "# 3D jerk\n",
    "sample = derive_jerk_smooth(speedcols, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assume that you decide to proceed differently. You load in your sample, flip and interpolate it, but you decide to smooth the data only after you get the derivates - so that you can smooth all columns in one go.\n",
    "\n",
    "Let's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the same sample\n",
    "sample_test = pd.read_csv(mtfiles[0])\n",
    "\n",
    "# drop visibility cols\n",
    "sample_test = sample_test.drop(sample_test.columns[sample_test.columns.str.contains('visibility',case = False)],axis = 1)\n",
    "\n",
    "# flip the data\n",
    "sample_test = flip_data(sample_test)\n",
    "\n",
    "# interpolate the data\n",
    "sample_test = interpolate(sample_test)\n",
    "\n",
    "# now derive\n",
    "cols = sample_test.columns\n",
    "cols = cols.drop(['time'])\n",
    "\n",
    "# 3D speed\n",
    "speedcols, sample_test = derive_speed_smooth(cols, sample_test, sr)\n",
    "\n",
    "# 3D acceleration\n",
    "sample_test = derive_accel_smooth(speedcols, sample_test)\n",
    "\n",
    "# 3D jerk\n",
    "sample_test = derive_jerk_smooth(speedcols, sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect whether the order matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is speed of first smoothed, then derivated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['RIGHT_WRIST_speed'].plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is speed of first derivated, then smoothed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test['RIGHT_WRIST_speed'].plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the acceleration of the first smoothed, then derivated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['RIGHT_WRIST_acceleration'].plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the acceleration of the first derivated, then smoothed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test['RIGHT_WRIST_acceleration'].plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the order matters. Differentiating multiplies the noise present in a signal, so before **every** differentiation, we want to make sure our data are *relatively* clean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we performed all steps that are necessary to get nice, clean data ready for analysis - on a **single** file. But we have more of them ready.\n",
    "\n",
    "Luckily, because we have all the steps in functions, we can just apply them to all files in a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know look at the sample dataframe, is there something we might be missing for future use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code to process every file in Output_TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import platform  # To detect the operating system\n",
    "\n",
    "# Get the current working directory\n",
    "curfolder = os.getcwd()\n",
    "\n",
    "# Check the OS type and set folder paths accordingly\n",
    "if user == \"Windows\":\n",
    "    mtfolder = curfolder + '\\\\..\\\\..\\\\01_MotionCapture\\\\Mediapipe\\\\Output_TimeSeries\\\\'\n",
    "    processedfolder = curfolder + '\\\\TS_processed\\\\'\n",
    "elif user == \"Mac\":  # Darwin is macOS\n",
    "    mtfolder = os.path.join(curfolder, '..', '..', '01_MotionCapture', 'Mediapipe', 'Output_TimeSeries')\n",
    "    processedfolder = os.path.join(curfolder, 'TS_processed')\n",
    "else:\n",
    "    raise SystemError(\"Unsupported operating system\")\n",
    "\n",
    "# Get all the files in the folder\n",
    "mtfiles = glob.glob(os.path.join(mtfolder, '*body_world.csv'))\n",
    "\n",
    "# If the folder TS_processed does not exist, create it\n",
    "if not os.path.exists(processedfolder):\n",
    "    os.makedirs(processedfolder, exist_ok=True)\n",
    "\n",
    "for file in mtfiles:\n",
    "    fileID = os.path.basename(file).split('.')[0]  # More OS-friendly way to extract fileID\n",
    "    print('working on:', fileID)\n",
    "\n",
    "    # Load the file\n",
    "    sample = pd.read_csv(file)\n",
    "\n",
    "    # Drop visibility columns\n",
    "    sample = sample.drop(sample.columns[sample.columns.str.contains('visibility', case=False)], axis=1)\n",
    "\n",
    "    # Flip the data\n",
    "    sample = flip_data(sample)\n",
    "\n",
    "    # Interpolate the data\n",
    "    sample = interpolate(sample)\n",
    "\n",
    "    # Smooth the data\n",
    "    sample = smooth_data(sample)\n",
    "\n",
    "    # Derive speed, acceleration, jerk\n",
    "    cols = sample.columns.drop(['time'])\n",
    "    speedcols, sample = derive_speed_smooth(cols, sample, sr)\n",
    "    sample = derive_accel_smooth(speedcols, sample)\n",
    "    sample = derive_jerk_smooth(speedcols, sample)\n",
    "\n",
    "    # Save it\n",
    "    sample.to_csv(os.path.join(processedfolder, f'{fileID}.csv'), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTworkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
